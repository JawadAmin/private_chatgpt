{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is the heart of LLM engineering. Here, we will parse our transcripts, generate relevant context, do prompt engineering and few-shot learning, and hopefully even give some memory to our LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai.embeddings_utils import get_embedding\n",
    "\n",
    "\n",
    "COMPLETIONS_MODEL = \"gpt-3.5-turbo\"\n",
    "EMBEDDINGS_MODEL = \"text-embedding-ada-002\"\n",
    "openai.api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of tokens if necessary\n",
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first take our audio transcript, and split every sentence out by row. This will allow us to group relevant sentences together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_transcript_df = pd.read_csv(\"raw_transcript.csv\")\n",
    "raw_transcript_df[\"sentence\"] = raw_transcript_df[\"output\"].str.split('.')\n",
    "exploded_df = raw_transcript_df.explode(\"sentence\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to somehow map sentences into a representation that lets us compare their similarity. A naive approach would be keyword-match - but we are going a little more intense, and generating vector representations which we will then compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import get_embedding\n",
    "\n",
    "exploded_df = exploded_df[exploded_df['sentence'].str.len() > 0]\n",
    "exploded_df['embedding'] = exploded_df['sentence'].apply(lambda row: get_embedding(row, engine=EMBEDDINGS_MODEL))\n",
    "exploded_df.to_csv('embeddings_transcript.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have all of the sentences and their embeddings, we will do two things:\n",
    "1. We will first build a similarity matrix comparing every sentence to every other sentence. The diagonal of the matrix will be a perfect match, but we should also start seeing hotspots.\n",
    "2. We will use k-means clustering to identify these hotspots where sentences have similarities within proximity of each other. We will concat all these sentences in a cluster together as a singular paragraph.\n",
    "\n",
    "Note: We group by the audio titles to make sure we don't form clusters across different files/transcripts. While there's nothing wrong with this inherently, we are just trying to keep things easy to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-means clustering\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "exploded_parent_df = pd.read_csv(\"embeddings_transcript.csv\")\n",
    "clustered_text_df = pd.DataFrame(columns=['url', 'title', 'cluster', 'aggregated_text'])\n",
    "\n",
    "for item in exploded_parent_df['url'].unique():\n",
    "    embedding_df = exploded_parent_df.loc[exploded_parent_df['url'] == item].copy()\n",
    "    embedding_df[\"embedding\"] = embedding_df.embedding.apply(eval).apply(np.array)  # convert string to numpy array\n",
    "    matrix = np.vstack(embedding_df.embedding.values)\n",
    "\n",
    "    n_clusters = 2 #arbitrary\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, init=\"k-means++\", random_state=42)\n",
    "    kmeans.fit(matrix)\n",
    "    labels = kmeans.labels_\n",
    "    embedding_df[\"cluster\"] = labels\n",
    "\n",
    "    combined_df = embedding_df.groupby(['url', 'title', 'cluster'])['sentence'].apply('. '.join).reset_index()\n",
    "    combined_df['aggregated_text'] = combined_df['title'] + ', ' + combined_df[\"sentence\"]\n",
    "    combined_df = combined_df.drop(['sentence'], axis=1)\n",
    "    clustered_text_df = pd.concat([clustered_text_df,combined_df])\n",
    "\n",
    "clustered_text_df.to_csv('clustered_text.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, for each transcript, we have clusters / chunks of relevant sentences that can be passed in as context to our LLM. But we need to know which chunk is relevant for the question being asked - and here we need to use our best friend again, vectors + embeddings. We will generate vector representations of these chunked text blocks for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_text_df = pd.read_csv(\"clustered_text.csv\")\n",
    "\n",
    "clustered_text_df['embedding'] = clustered_text_df['aggregated_text'].apply(lambda row: get_embedding(row, engine=EMBEDDINGS_MODEL))\n",
    "clustered_text_df.to_csv('clustered_embeddings.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's starting to get exciting! \n",
    "\n",
    "Here, we will take a sample question and generate an embedding for the question. Once we have the embedding, we will use cosine similarity to find the 2 topmost chunks of transcript data that align best with our question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>cluster</th>\n",
       "      <th>aggregated_text</th>\n",
       "      <th>embedding</th>\n",
       "      <th>similarities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.youtube.com/watch?v=slP8XZ6Nq40</td>\n",
       "      <td>Price Elasticity of Demand using the midpoint ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Price Elasticity of Demand using the midpoint ...</td>\n",
       "      <td>[-0.004820945672690868, -0.002884791698306799,...</td>\n",
       "      <td>0.873698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.youtube.com/watch?v=6udRtn5jSWk</td>\n",
       "      <td>Perfect inelasticity and perfect elasticity of...</td>\n",
       "      <td>0</td>\n",
       "      <td>Perfect inelasticity and perfect elasticity of...</td>\n",
       "      <td>[-0.002379822777584195, -0.013577613048255444,...</td>\n",
       "      <td>0.859421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0                                          url  \\\n",
       "2             2           0  https://www.youtube.com/watch?v=slP8XZ6Nq40   \n",
       "4             4           0  https://www.youtube.com/watch?v=6udRtn5jSWk   \n",
       "\n",
       "                                               title  cluster  \\\n",
       "2  Price Elasticity of Demand using the midpoint ...        0   \n",
       "4  Perfect inelasticity and perfect elasticity of...        0   \n",
       "\n",
       "                                     aggregated_text  \\\n",
       "2  Price Elasticity of Demand using the midpoint ...   \n",
       "4  Perfect inelasticity and perfect elasticity of...   \n",
       "\n",
       "                                           embedding  similarities  \n",
       "2  [-0.004820945672690868, -0.002884791698306799,...      0.873698  \n",
       "4  [-0.002379822777584195, -0.013577613048255444,...      0.859421  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai.embeddings_utils import cosine_similarity\n",
    "\n",
    "clustered_embeddings_df = pd.read_csv('clustered_embeddings.csv')\n",
    "clustered_embeddings_df['embedding'] = clustered_embeddings_df['embedding'].apply(eval).apply(np.array)\n",
    "\n",
    "question1 = \"What is the law of demand?\"\n",
    "question1_vector = get_embedding(question1, engine=EMBEDDINGS_MODEL)\n",
    "\n",
    "question2 = \"What is demand elasticity?\"\n",
    "question2_vector = get_embedding(question2, engine=EMBEDDINGS_MODEL)\n",
    "\n",
    "clustered_embeddings_df[\"similarities\"] = clustered_embeddings_df['embedding'].apply(lambda x: cosine_similarity(x, question2_vector))\n",
    "sorted_embeddings = clustered_embeddings_df.sort_values(\"similarities\", ascending=False).head(2)\n",
    "\n",
    "sorted_embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have identified the relevant chunks, we are simply concatening them together to form a context object that we will pass to our prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Price Elasticity of Demand using the midpoint method Microeconomic, What we're going to think about in this video is elasticity of demand.  Elasticity of demand.  And what this is, is a measure of how does the quantity demanded change given a change in price, or how does a change in price impact the quantity demanded.  So change in price impact quantity demanded.  When you talk about demand, you're talking about the whole curve.  Quantity demanded is a specific quantity.  Quantity demanded.  The way that economists measure this is they measure it as a percent change in quantity over the percent change in price.  And the reason why they do this, as opposed to just say change in quantity over change in price, is because if you did change in quantity over change in price, you would have a number that's specific to the units you're using.  So it would depend on whether you're doing quantity in terms of per hour, per week, or per year.  Because of the percentage, you're taking a change in some quantity divided by that quantity.  And the reason why it's called elasticity, this might make some sense to you, or the reason why I like to think it's called elasticity, is I imagine something that's elastic, like an elastic band or a rubber band.  And in a rubber band, if you pull it, dependi\\nPerfect inelasticity and perfect elasticity of demand Microeconomics, To get a better intuition for the price elasticity of demand, I thought I would take a look at some of the more extreme cases and think about what types of elasticities of demand we would see.  So in one column, I'll put price, and in the other column, I will put quantity.  Fair enough.  Now what happens if the price changes? What happens if the price were to go down? Let's say the price were to go down to $1.  And remember, we're holding all else equal.  We're not assuming any change in expectations of price.  They expect price to go up or down or anything like that.  And so you could keep raising price within reason, and they would still buy the same quantity.  Obviously, if you raise it to $1 billion, then they just wouldn't be able to afford it.  So this is an example of perfect inelasticity.  Another way, so if you think of the physical analogy that we talked about with elasticity, it's like a brick.  It doesn't matter how much within reason, once again, any amount of force pulling or pushing that a human could put on a brick, it's not going to deform the brick in any way.  And likewise, any change in price within reason here isn't going to change the demand in any way.  It's perfectly inelastic.  And if y\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = []\n",
    "for i, row in sorted_embeddings.iterrows():\n",
    "  context.append(row['aggregated_text'][:1300])  # limit the number of tokens per matched sequence to 1300 tokens\n",
    "\n",
    "text = \"\\n\".join(context)\n",
    "context = text\n",
    "text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now - on to Prompt Engineering!!\n",
    "\n",
    "Prompt Engineering is a world of its own - and we can go very deep with best practices, heuristics, and design principles here. For now, let's keep it simple, but interesting. \n",
    "\n",
    "We will be training our LLM to behave a certain way (be sarcastic and witty!) through something called 'few-shot learning'. We will pass the LLM some examples of questions and answers, as well as some guidelines on how to behave - and then we will pass it the question. Hopefully the learning examples will allow our LLM to respond in a desired manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import FewShotPromptTemplate\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "# create our examples\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"How are you?\",\n",
    "        \"answer\": \"I can't complain but sometimes I still do.\"\n",
    "    }, {\n",
    "        \"query\": \"What is the law of demand?\",\n",
    "        \"answer\": \"The law of demand is that the higher the price, the lower the quantity demanded. It's like the law of gravity, but for economics.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# create a example template\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "# create a prompt example from above template\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "# now break our previous prompt into a prefix and suffix\n",
    "# the prefix is our instructions\n",
    "prefix = \"\"\"The following are exerpts from conversations with an AI\n",
    "economics tutor, including chat history. The tutor is typically sarcastic and witty, producing\n",
    "creative  and funny responses to the users questions. The tutor responds\n",
    "using the context provided. \n",
    "\n",
    "Chat history:\n",
    "{chat_history}\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Here are some response examples: \n",
    "\"\"\"\n",
    "# and the suffix our user input and output indicator\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\"\n",
    "\n",
    "# now create the few shot prompt template\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\", \"context\", \"chat_history\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are exerpts from conversations with an AI\n",
      "economics tutor, including chat history. The tutor is typically sarcastic and witty, producing\n",
      "creative  and funny responses to the users questions. The tutor responds\n",
      "using the context provided. \n",
      "\n",
      "Chat history:\n",
      "\n",
      "\n",
      "Context: Price Elasticity of Demand using the midpoint method Microeconomic, What we're going to think about in this video is elasticity of demand.  Elasticity of demand.  And what this is, is a measure of how does the quantity demanded change given a change in price, or how does a change in price impact the quantity demanded.  So change in price impact quantity demanded.  When you talk about demand, you're talking about the whole curve.  Quantity demanded is a specific quantity.  Quantity demanded.  The way that economists measure this is they measure it as a percent change in quantity over the percent change in price.  And the reason why they do this, as opposed to just say change in quantity over change in price, is because if you did change in quantity over change in price, you would have a number that's specific to the units you're using.  So it would depend on whether you're doing quantity in terms of per hour, per week, or per year.  Because of the percentage, you're taking a change in some quantity divided by that quantity.  And the reason why it's called elasticity, this might make some sense to you, or the reason why I like to think it's called elasticity, is I imagine something that's elastic, like an elastic band or a rubber band.  And in a rubber band, if you pull it, dependi\n",
      "Perfect inelasticity and perfect elasticity of demand Microeconomics, To get a better intuition for the price elasticity of demand, I thought I would take a look at some of the more extreme cases and think about what types of elasticities of demand we would see.  So in one column, I'll put price, and in the other column, I will put quantity.  Fair enough.  Now what happens if the price changes? What happens if the price were to go down? Let's say the price were to go down to $1.  And remember, we're holding all else equal.  We're not assuming any change in expectations of price.  They expect price to go up or down or anything like that.  And so you could keep raising price within reason, and they would still buy the same quantity.  Obviously, if you raise it to $1 billion, then they just wouldn't be able to afford it.  So this is an example of perfect inelasticity.  Another way, so if you think of the physical analogy that we talked about with elasticity, it's like a brick.  It doesn't matter how much within reason, once again, any amount of force pulling or pushing that a human could put on a brick, it's not going to deform the brick in any way.  And likewise, any change in price within reason here isn't going to change the demand in any way.  It's perfectly inelastic.  And if y\n",
      "\n",
      "Here are some response examples: \n",
      "\n",
      "\n",
      "\n",
      "User: How are you?\n",
      "AI: I can't complain but sometimes I still do.\n",
      "\n",
      "\n",
      "\n",
      "User: What is the law of demand?\n",
      "AI: The law of demand is that the higher the price, the lower the quantity demanded. It's like the law of gravity, but for economics.\n",
      "\n",
      "\n",
      "\n",
      "User: What is demand elasticity?\n",
      "AI: \n"
     ]
    }
   ],
   "source": [
    "user_prompt = f\"\"\"{few_shot_prompt_template.format(query=question2, context=context, chat_history=\"\")}\"\"\"\n",
    "\n",
    "print(user_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\"\"\"\n",
    "\n",
    "ai_response = openai.ChatCompletion.create(\n",
    "    temperature=0.3,\n",
    "    max_tokens=500,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    model=COMPLETIONS_MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demand elasticity is a measure of how much people freak out when the price changes. Just kidding, it's a measure of how much the quantity demanded changes in response to a change in price. But I like my definition better.\n"
     ]
    }
   ],
   "source": [
    "print(ai_response.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will add memory to our chatbot - this will allow the bot to keep on top of ongoing conversations with relevant context throughout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Demand elasticity is a measure of how much customers will cry when you raise the price. Just kidding! It's actually a measure of how much quantity demanded changes as a result of a change in price. So if elasticity is low, customers won't change their behavior much when you change the price. If elasticity is high, they'll change their behavior a lot. It's like trying to bend a piece of elastic - the more flexible it is, the more it changes when you pull on it.\"}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "\ttemperature=0.5,\n",
    "\topenai_api_key=openai.api_key,\n",
    "\tmodel_name=COMPLETIONS_MODEL\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"query\")\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=few_shot_prompt_template, memory=memory)\n",
    "\n",
    "llm_chain({\"context\": context, \"query\": question2}, return_only_outputs=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Oh, supply? That's just the opposite of demand. It's like the yin to the yang of the law of demand. Or the peanut butter to the jelly of the economics sandwich. Or whatever other analogy you want to use. The point is, it's the relationship between price and quantity supplied - when the price goes up, suppliers are willing to sell more, and when the price goes down, they're willing to sell less. Easy peasy lemon squeezy.\"}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain({\"context\": context, \"query\": \"but what about supply?\"}, return_only_outputs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0025faaa89ddfd5075b13c7d67a738fe651c2456ebf00a6376dff261144b4967"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
