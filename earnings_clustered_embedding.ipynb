{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "COMPLETIONS_MODEL = \"gpt-3.5-turbo\"\n",
    "EMBEDDINGS_MODEL = \"text-embedding-ada-002\"\n",
    "openai.api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of tokens if necessary\n",
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_transcript_df = pd.read_csv(\"raw_transcript.csv\")\n",
    "raw_transcript_df[\"sentence\"] = raw_transcript_df[\"output\"].str.split('.')\n",
    "exploded_df = raw_transcript_df.explode(\"sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import get_embedding\n",
    "\n",
    "exploded_df = exploded_df[exploded_df['sentence'].str.len() > 0]\n",
    "exploded_df['embedding'] = exploded_df['sentence'].apply(lambda row: get_embedding(row, engine=EMBEDDINGS_MODEL))\n",
    "exploded_df.to_csv('embeddings_transcript.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-means clustering\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "exploded_parent_df = pd.read_csv(\"embeddings_transcript.csv\")\n",
    "clustered_text_df = pd.DataFrame(columns=['url', 'title', 'cluster', 'aggregated_text'])\n",
    "\n",
    "for item in exploded_parent_df['url'].unique():\n",
    "    embedding_df = exploded_parent_df.loc[exploded_parent_df['url'] == item].copy()\n",
    "    embedding_df[\"embedding\"] = embedding_df.embedding.apply(eval).apply(np.array)  # convert string to numpy array\n",
    "    matrix = np.vstack(embedding_df.embedding.values)\n",
    "\n",
    "    n_clusters = 10 #arbitrary\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, init=\"k-means++\", random_state=42)\n",
    "    kmeans.fit(matrix)\n",
    "    labels = kmeans.labels_\n",
    "    embedding_df[\"cluster\"] = labels\n",
    "\n",
    "    combined_df = embedding_df.groupby(['url', 'title', 'cluster'])['sentence'].apply('. '.join).reset_index()\n",
    "    combined_df['aggregated_text'] = combined_df['title'] + ', ' + combined_df[\"sentence\"]\n",
    "    combined_df = combined_df.drop(['sentence'], axis=1)\n",
    "    clustered_text_df = pd.concat([clustered_text_df,combined_df])\n",
    "\n",
    "clustered_text_df.to_csv('clustered_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_text_df = pd.read_csv(\"clustered_text.csv\")\n",
    "\n",
    "clustered_text_df['embedding'] = clustered_text_df['aggregated_text'].apply(lambda row: get_embedding(row, engine=EMBEDDINGS_MODEL))\n",
    "clustered_text_df.to_csv('clustered_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import cosine_similarity\n",
    "\n",
    "clustered_embeddings_df = pd.read_csv('clustered_embeddings.csv')\n",
    "clustered_embeddings_df['embedding'] = clustered_embeddings_df['embedding'].apply(eval).apply(np.array)\n",
    "\n",
    "question1 = \"How did Adobe perform this quarter?\"\n",
    "question1_vector = get_embedding(question1, engine=EMBEDDINGS_MODEL)\n",
    "\n",
    "question2 = \"How is PagerDuty using and planning to use AIOps?\"\n",
    "question2_vector = get_embedding(question2, engine=EMBEDDINGS_MODEL)\n",
    "\n",
    "clustered_embeddings_df[\"similarities\"] = clustered_embeddings_df['embedding'].apply(lambda x: cosine_similarity(x, question2_vector))\n",
    "sorted_embeddings = clustered_embeddings_df.sort_values(\"similarities\", ascending=False).head(3)\n",
    "\n",
    "sorted_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = []\n",
    "for i, row in sorted_embeddings.iterrows():\n",
    "  context.append(row['aggregated_text'][:1300])  # limit the number of tokens per matched sequence to 1300 tokens\n",
    "\n",
    "text = \"\\n\".join(context)\n",
    "context = text\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"Answer the following question using only the context provided. Answer in the style of a financial analyst. If you don't know the answer for certain, say I don't know.\"\"\"\n",
    "\n",
    "user_prompt = f\"\"\"\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Q: {question2}\n",
    "A:\"\"\"\n",
    "\n",
    "openai.ChatCompletion.create(\n",
    "    temperature=0.2,\n",
    "    max_tokens=700,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    model=COMPLETIONS_MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
